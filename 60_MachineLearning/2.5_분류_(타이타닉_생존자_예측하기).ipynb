{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDZtQMdNLIm6"
      },
      "source": [
        "# 1. 복습하기\n",
        "\n",
        "* ( Feature Scaling ) : 서로 다른 변수의 값의 범위를 일정한 수준으로 맞추는 작업으로 ( 정규화 )와 ( 표준화 )가 있습니다.\n",
        "\n",
        "* ( 정규화 ) : 최소 ~ 최대 범위로 스케일 변환을 하는 것으로 대부분 0 ~ 1 범위에 맞추는 것을 의미합니다. 사이킷런의 정규화를 위한 클래스는? ( MinMaxScaler )\n",
        "\n",
        "* ( 표준화 ) : 특성의 평균을 0으로 맞추고 분산을 1로 만들어 정규 분포와 같은 특징을 가지도록 합니다. 사이컷런의 표준화를 위한 클래스는? ( StandardScaler )\n",
        "\n",
        "* 피처 스케일링 시 주의사항은? ( 학습데이터로 Fit 한 후, ... )\n",
        "\n",
        "* ( 로지스틱 회귀 )는 선형 회귀 방식을 기반으로 데이터가 어떤 범주에 속할 확률을 0 ~ 1 사이의 값으로 예측하고 그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 분류해주는 알고리즘 입니다.\n",
        "\n",
        "* 로지스틱 회귀는 ( 시그모이드 ) 함수를 이용하여 x값이 아무리 커지거나 작아져도 y값이 항상 0과 1사이의 값이 되도록 반환해 줍니다.\n",
        "\n",
        "* 사이킷런에서 제공하는 로지스틱 회귀를 위한 클래스는? ( LogisticRegression )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAMbE7-cBZrw"
      },
      "source": [
        "# 2. 데이터 가져오기\n",
        "\n",
        "* kaggle.com에서 타이타닉 데이터셋 가져오기 [캐글](https://www.kaggle.com/c/titanic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j88SYLox5WUZ"
      },
      "outputs": [],
      "source": [
        "# 데이터 불러오기\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# train_df = pd.read_csv('/content/drive/MyDrive/datasets/titanic/train.csv', index_col='PassengerId')\n",
        "# test_df = pd.read_csv('/content/drive/MyDrive/datasets/titanic/test.csv', index_col='PassengerId')\n",
        "train_df = pd.read_csv('./titanic/train.csv', index_col='PassengerId')\n",
        "test_df = pd.read_csv('./titanic/test.csv', index_col='PassengerId')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9rqO_iZ8vAA"
      },
      "outputs": [],
      "source": [
        "# 앞 데이터 보기1\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDorLYH88xMG"
      },
      "outputs": [],
      "source": [
        "# 앞 데이터 보기2\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IZnFYNw7ppi"
      },
      "outputs": [],
      "source": [
        "# 열 정보 보기1\n",
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2et7jYN9Cqp"
      },
      "outputs": [],
      "source": [
        "# 열 정보 보기2\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YCASD7gCJ78"
      },
      "outputs": [],
      "source": [
        "# Null 건수 보기1\n",
        "train_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR7T8kOUk-zf"
      },
      "outputs": [],
      "source": [
        "# Null 건수 보기2\n",
        "test_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAdjlWG0Nthf"
      },
      "source": [
        "# 3. 데이터 전처리하기\n",
        "\n",
        "* 머신러닝 알고리즘은 Null값과 문자열 값을 입력값으로 허용하지 않습니다.\n",
        "\n",
        "* Null값 처리하기\n",
        "  * Null값이 얼마 되지 않는다면 피처의 평균값 또는 중앙값으로 대체할 수 있음\n",
        "  * Null값이 대부분이라면 해당 피처는 Drop하는 것이 좋음\n",
        "  * 위의 경우가 아니라면 더 정밀하게 대체값을 선정해야 함\n",
        "\n",
        "* 범주형 데이터 변환하기 : 학습에 필요한 모든 문자열 값은 인코딩되어 숫자형으로 변환해야 함\n",
        "\n",
        "* 불필요한 피처 삭제하기 : 예) 단순 아이디와 같은 식별자 피처"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_sPTUZORNY7"
      },
      "source": [
        "## 3-1. Null값 처리하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nkdfunaw_B7L"
      },
      "outputs": [],
      "source": [
        "# Age : 중앙값으로 채우기\n",
        "train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
        "test_df['Age'].fillna(test_df['Age'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPwrq4mdS04n"
      },
      "outputs": [],
      "source": [
        "# Cabin : 삭제\n",
        "train_df.drop(['Cabin'], axis=1, inplace=True)\n",
        "test_df.drop(['Cabin'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQXl0x3ATCEF"
      },
      "outputs": [],
      "source": [
        "# Embarked : 건수 확인하기\n",
        "train_df['Embarked'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3ah9mAxTO_G"
      },
      "outputs": [],
      "source": [
        "# Embarked : 가장 건수가 많은 데이터로 채우기\n",
        "train_df['Embarked'].fillna('S', inplace=True)\n",
        "test_df['Embarked'].fillna('S', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72hN5KV-lXGA"
      },
      "outputs": [],
      "source": [
        "# Fare : 중앙값으로 채우기\n",
        "test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1JGkbyCHRLQ"
      },
      "outputs": [],
      "source": [
        "# Null 건수 보기1\n",
        "train_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjsINX5plnnU"
      },
      "outputs": [],
      "source": [
        "# Null 건수 보기2\n",
        "test_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ExEH188RSQE"
      },
      "source": [
        "## 3-2. 범주형 데이터 변환하기\n",
        "\n",
        "* 머신러닝에서는 학습에 필요한 문자열값은 인코딩되어 수치형 데이터로 변환해 주어야 합니다.\n",
        "\n",
        "* 만약에 봄을 1, 여름을 2, 가을을 3, 겨울을 4로 변환하게 되면 어떻게 될까요?\n",
        "\n",
        "* (   ) : 피처 값의 유형에 따라 새로운 피처를 추가하여 고유값에 해당하는 컬럼에만 1을 표시하고 나머지 칼럼에는 0을 표시하는 방식입니다.\n",
        "\n",
        "* 이렇게 되면 더미로 만든 가변수로 변환하여 관계성이 생기지 않게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1t7oR7qdBLH"
      },
      "outputs": [],
      "source": [
        "# 범주형 데이터 : Pclass, Sex, Embarked\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwH9dWEkKRPO"
      },
      "outputs": [],
      "source": [
        "# get_dummies 함수 알아보기\n",
        "season = pd.DataFrame({\n",
        "    'season':['spring', 'summer', 'fall', 'winter']\n",
        "})\n",
        "season"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuulY4zQqixV"
      },
      "outputs": [],
      "source": [
        "pd.get_dummies(season['season'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TczTFddfR-Iz"
      },
      "outputs": [],
      "source": [
        "# 원-핫 인코딩\n",
        "train_df = pd.get_dummies(train_df, columns=['Pclass', 'Sex', 'Embarked'])\n",
        "test_df = pd.get_dummies(test_df, columns=['Pclass', 'Sex', 'Embarked'])\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDm--I6AUgUy"
      },
      "source": [
        "## 3-3. 불필요한 피처 삭제하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "028G2vT7Um_f"
      },
      "outputs": [],
      "source": [
        "# 불필요한 피처 삭제하기\n",
        "drop_cols = ['Name', 'Ticket']\n",
        "train_df.drop(drop_cols, axis=1, inplace=True)\n",
        "test_df.drop(drop_cols, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj4iU-UMXqDF"
      },
      "outputs": [],
      "source": [
        "# 데이터 확인하기1\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgBpEgKpXrrv"
      },
      "outputs": [],
      "source": [
        "# 데이터 확인하기2\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkR1AqCfL1PN"
      },
      "source": [
        "# 4. 데이터 분리하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUcctdW7XpKZ"
      },
      "outputs": [],
      "source": [
        "# 데이터 분리하기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_all = train_df.drop('Survived', axis=1)\n",
        "y_train_all = train_df['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_all, y_train_all, test_size=0.2, random_state=11)\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVizn8mybB8_"
      },
      "source": [
        "# 5. 모델 선택 및 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM9XCFf3Iy5l"
      },
      "outputs": [],
      "source": [
        "# 사이킷런 알고리즘 import하기\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDhrFwntbRDN"
      },
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "params = {\n",
        "    'max_depth': [4, 6, 8, 10, 12],\n",
        "    'min_samples_split': [2, 3, 4]\n",
        "}\n",
        "dt = DecisionTreeClassifier(random_state=11)\n",
        "\n",
        "gs1 = GridSearchCV(dt, param_grid=params, n_jobs=-1)\n",
        "\n",
        "gs1.fit(X_train, y_train)\n",
        "\n",
        "print('best parameter:', gs1.best_params_)\n",
        "print('best score:', gs1.best_score_)\n",
        "print(gs1.score(X_train, y_train))\n",
        "print(gs1.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K8qWRm9eOnq"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "params = {  \n",
        "    'max_depth': [4, 6, 8, 10, 12],\n",
        "    'min_samples_split': [2, 3, 4],\n",
        "    'n_estimators': [100, 125, 150]\n",
        "}\n",
        "rf = RandomForestClassifier(random_state=11)\n",
        "\n",
        "gs2 = GridSearchCV(rf, param_grid=params, n_jobs=-1)\n",
        "\n",
        "gs2.fit(X_train, y_train)\n",
        " \n",
        "print('best parameter:', gs2.best_params_)\n",
        "print('best score:', gs2.best_score_)\n",
        "print(gs2.score(X_train, y_train))\n",
        "print(gs2.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eS23CoN8eUa3"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "params = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.01, 0.1, 1, 5, 10],\n",
        "    'max_iter': [500, 750, 1000]\n",
        "}\n",
        "lr = LogisticRegression()\n",
        "\n",
        "gs3 = GridSearchCV(lr, param_grid=params, n_jobs=-1)\n",
        "\n",
        "gs3.fit(X_train, y_train)\n",
        "\n",
        "print('best parameter:', gs3.best_params_)\n",
        "print('best score:', gs3.best_score_)\n",
        "print(gs3.score(X_train, y_train))\n",
        "print(gs3.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4hP1G6ihTM0"
      },
      "source": [
        "# 6. 모델 예측값 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h00XLxxOhVM7"
      },
      "outputs": [],
      "source": [
        "# test.csv : 2차원 배열로 변환하기\n",
        "pred_input = test_df.values\n",
        "pred_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c-l2XdKj76m"
      },
      "outputs": [],
      "source": [
        "# 모델 예측값 얻기\n",
        "best_dt = gs1.best_estimator_\n",
        "pred_dt = best_dt.predict(pred_input)\n",
        "\n",
        "best_rf = gs2.best_estimator_\n",
        "pred_rf = best_rf.predict(pred_input)\n",
        "\n",
        "best_lr = gs3.best_estimator_\n",
        "pred_lr = best_lr.predict(pred_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzZVjoDLl80Y"
      },
      "outputs": [],
      "source": [
        "# 파일 저장하기\n",
        "output = pd.DataFrame({\n",
        "    'PassengerId': test_df.index,\n",
        "    'Survived': pred_dt})\n",
        "\n",
        "output.to_csv('/content/drive/MyDrive/datasets/titanic/my_submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "2-5. 분류 (타이타닉 생존자 예측하기)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
